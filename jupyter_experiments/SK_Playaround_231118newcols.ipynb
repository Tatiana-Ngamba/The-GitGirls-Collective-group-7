{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0178d0-b9e1-4155-9e7f-a8c7923a4594",
   "metadata": {},
   "source": [
    "# Starter data joining/cleaning code (SK, 23 11 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f677041a-7fa0-4302-976b-c306a9104105",
   "metadata": {},
   "source": [
    "have tended to save a csv copy of every dataframe created, can take these out once happy with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d13a8-b9c3-4088-bc09-c4d005cbdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "# pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b000b88-2cfc-483c-99ff-528c696eea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main csv with salary data (local currency & gbp converted)\n",
    "sal_orig_df = pd.read_csv(\"output_playaround231128.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbf750-c01c-42c8-8435-f8a0fabda508",
   "metadata": {},
   "source": [
    "Bring in data from country_codes table, to merge with salaries data (NEED the country name, the country code is difficult to work with!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc730c2-8b0d-495f-9571-ed96bc1d04e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# mysql.connector or pymysql don't work with Jupyter / MySQl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f7a41-b949-4082-826e-d78222a3e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_codes.sql information is in an .sql table. Need to convert sql > db in order for pandas to turn into into DF. Then convert to csv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQl database connection details\n",
    "username = 'root'\n",
    "password = '' # complete this\n",
    "host = 'localhost'\n",
    "database = 'countries_db'\n",
    "\n",
    "# Creates a database engine\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\")\n",
    "\n",
    "# The SQL query to get all info from table named country_codes\n",
    "query = \"SELECT * FROM country_codes\"  \n",
    "\n",
    "# Use Pandas to load data into a DataFrame\n",
    "countries_df = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbb204-cc85-4c7e-8f6d-cdfd37e31a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countries_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d70985-dfc8-444f-b6ee-8def4f74b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df.to_csv(\"country_codes.csv\", encoding='utf-8', index=False) # save dataframe to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb42efb-443c-4d37-ad96-3cae0c6d01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer join salaries df to country_codes df on iso_alpha2\n",
    "sal_country_df = pd.merge(sal_orig_df, countries_df, on='iso_alpha2', how='outer')\n",
    "sal_country_df.to_csv(\"sal_and_country.csv\", index=False) # save dataframe to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48771b3-d983-4367-b5ae-f7c1bf37196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_country_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7221dd-83a1-4140-a0fc-514140dc6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_country_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f453622c-f721-4598-8be9-3139211a31c6",
   "metadata": {},
   "source": [
    "### Cleaning of merge salaries & country (codes) info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85e620-831e-4099-8448-1265dfcc25a5",
   "metadata": {},
   "source": [
    "Remove the excess rows from country_codes which aren't in our Teleport data. Identify the excess rows... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac377f1-d8ab-42a5-97d3-36a041c32552",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_country_df['salary_percentiles_percentile_50'].isnull().sum()\n",
    "# 53 country rows from country_codes don't have salary data (so weren't in Teleport API of 198 / 252 countries )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9749f-51c8-4781-bbac-a0081a867ef3",
   "metadata": {},
   "source": [
    "Want to grab the country codes which aren't needed (no salary data), put them in a DF, and export to a csv to keep a record, then delete them from the main df..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46558a3-63b7-48bc-a0d6-58156df89f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'salary_percentiles_percentile_50' is null\n",
    "countries_no_salaries_df = sal_country_df[sal_country_df['salary_percentiles_percentile_50'].isnull()]\n",
    "\n",
    "# Export the filtered DataFrame to a CSV file\n",
    "countries_no_salaries_df.to_csv('countries_no_salaries.csv', index=False) # should contain 53\n",
    "\n",
    "# Drop the filtered rows from the original DataFrame\n",
    "sal_country_df = sal_country_df.dropna(subset=['salary_percentiles_percentile_50'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc51f23-28e8-4c35-87fc-cd098c13846e",
   "metadata": {},
   "source": [
    "### Merge gender pay column in with the main salary_country df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48122caa-c34a-4b7d-a6c2-cc92bbc18412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the gender_pay_parity csv column\n",
    "gender_df = pd.read_csv(\"Gender Pay Gap.csv\")\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfa80c-aeeb-4873-8ae4-80602335b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning: rename Country to country / Gender_Pay_Parity gender_pay_parity to facilitate merge\n",
    "gender_df.rename(columns={'Country': 'country', 'Gender_Pay_Parity':'gender_pay_parity'}, inplace=True)\n",
    "gender_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2154a9-11c8-4a35-8a54-f29ad362722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join main salary_country DF with gender_gap column\n",
    "sal_country_gender_df = pd.merge(gender_df, sal_country_df, on='country', how='outer')\n",
    "sal_country_gender_df.to_csv(\"sal_and_country_and_gender.csv\", index=False) # save dataframe to .csv file\n",
    "sal_country_gender_df.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ee8af-5f35-45d7-b326-43e9de769017",
   "metadata": {},
   "source": [
    "Need to look through the now triple-joined df and look for any odd rows where the country name from gender_pay_parity didn't match the spelling of the country name in salary_countries (it wasn't joined on iso_alpha2 code (it wasn't in gender_pay.csv), it was joined on name which is will have more variation).  \n",
    "Options: clean the country names before the merge to make sure they match. Or, import from an SQL table (as this will have been properly processed)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f53ab6ab-e963-4113-a654-716871231284",
   "metadata": {},
   "source": [
    "Need to clean these names, if they are still in the dataset \n",
    "CuraÃ§ao\tWillemstad\n",
    "Ã…land\tMariehamn\n",
    "Saint BarthÃ©lemy\tGustavia\n",
    "RÃ©union\tSaint-Denis\n",
    "SÃ£o TomÃ© and PrÃ­ncipe\n",
    "\n",
    "# Define the dodgy characters to search for\n",
    "dodgy_character = 'Ã' AND .... \n",
    "\n",
    "# Create a boolean mask to identify rows with the dodgy character in any field\n",
    "mask = df.apply(lambda x: x.str.contains(dodgy_character)).any(axis=1)\n",
    "\n",
    "# Get the rows with the dodgy character\n",
    "dodgy_rows = df[mask]\n",
    "\n",
    "# Print or process the dodgy rows\n",
    "print(dodgy_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14241359-87d0-43f6-8dcc-166b41520c6c",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df760a4-98c9-446f-b493-bff7c8ec5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sal_country_df.isna().sum() # something wrong: it's saying no NaN values # 156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffb0ae-eada-4d8a-b001-5a8f1c835096",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = sal_country_df.dtypes\n",
    "data_types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
